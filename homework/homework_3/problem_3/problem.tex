\documentclass{article}
\usepackage{amsmath, amssymb}
\usepackage{mathhint}
\usepackage{listings}

\begin{document}

% Set the context for this problem - this information appears in the page header
% and helps the hint system understand what material you've covered
\mathhintcontext{
  book=Guckenheimer and Holmes,
  chapter=1,
  section=1.5-1.8,
  problem=3,
  lectures={lecture_5.tex, lecture_6.tex}
}

\begin{problem}
Consider the following second-order, periodically forced, differential equation:
\begin{equation}\label{eq:prob_3}
  \ddot{x}+\delta\dot{x}+f(x)=\gamma\cos\left(\omega t\right).
\end{equation}
\begin{itemize}
  \item[(a)] Letting $f(x)=x$ and fixing $\omega=1,\delta>0,\gamma>0$, show that there exists a $2\pi$-periodic solution to (\ref{eq:prob_3}).
  \item[(b)] Construct a Poincaré map that takes $(x(0),\dot{x}(0))$ to $(x(T),\dot{x}(T))$, where $T=2\pi/\omega$ is the forcing period, and use this map to investigate the stability of the periodic orbit you found in part (a).
  \item[(c)] Now let $f(x)=\sin x$, and fix $\delta=\gamma=0$. Show that (\ref{eq:prob_3}) possess a homoclinic orbit $q^0(t)$ to a hyperbolic saddle point $p_0$. [\textit{Hint:} Recognize that the system is Hamiltonian and use the conserved quantity.]
  \item[(d)] Now let $\delta,\gamma>0$, and consider how this perturbation might affect the fixed point $p_0$ and the homoclinic orbit. Under the periodic forcing, the fixed point $p_0$ is perturbed to a \textit{periodic orbit} (of saddle type). This periodic orbit is a fixed point of the Poincaré map that takes $(x(0),\dot{x}(0))$ to $(x(T),\dot{x}(T))$. Find an approximation to this periodic orbit numerically (e.g., in Python or Matlab), by constructing a numerical approximation to the Poincaré map, and using a numerical root finder to find a fixed point close to $p_0$.
  \item[(e)] Now investigate (numerically) what happens to the homoclinic orbit $q^0(t)$, for $\delta,\gamma>0$. Do your best to numerically approximate the stable and unstable manifolds of the fixed point you found in the previous part, for some values of $\delta,\gamma,\omega$: for instance, place a bunch of points along the stable and unstable eigenspaces, and iterate them forward or backward using your Poincaré map. Can you find values for which the stable and unstable manifolds have transversal intersections? If so, can you find something resembling ``chaotic'' behavior?\newline [\textit{Hint:} In the coming weeks, we will learn a technique for predicting when such transversal intersections occur, and if $\delta,\gamma\ll 1$, this theory predicts that transversal intersections occur when \[\frac{\gamma}{\delta}>\frac{4}{\pi}\cosh\left(\frac{\pi\omega}{2}\right).\] Let this guide your numerical explorations.]
\end{itemize}

\end{problem}

\begin{notes}
From office hours, I learned that the Poincaré map is just the time $T$ map.

\section{Part (a)}

To show that a $2\pi$-periodic solution to (\ref{eq:prob_3}) exists, let's use the method of undetermined coefficients where we guess that $x(t)$ is 
\[ x(t)=A\cos\left( t\right) + B\sin\left( t\right) \]
and then we can compute the following values 
\begin{align*}
  \dot{x}&=-A\sin\left( t\right)+B\cos\left( t\right)\\
  \ddot{x}&=-A\cos\left( t\right) - B\sin\left( t\right)
\end{align*}
Now we can through our values into the following equation 
\[\ddot{x}+\delta\dot{x}+x=\gamma\cos\left( t\right)\]
to get 
\begin{align*}
  \gamma\cos\left( t\right)&=-A\cos\left( t\right) - B\sin\left( t\right)+\delta\left(-A\sin\left( t\right)+B\cos\left( t\right)\right)+A\cos\left( t\right) + B\sin\left( t\right)\\
  &=-A\delta\sin(t)+B\delta\cos(t)
\end{align*}
where $A=0$ and $B=\frac{\gamma}{\delta}$. Hence our $2\pi$-periodic solution to (\ref{eq:prob_3}) is 
\[x(t)=\frac{\gamma}{\delta}\sin(t) \]

\mathhint{Nudge}{2026-02-17 17:37}{Your work on part (a) looks correct — nice job finding the particular solution. You're on the right track to continue with the remaining parts!}

\section{Part (b)}

First, let's reparameterize our system such that it is an autonomous system of ODEs:
\begin{align*}
  \dot{x}&=y\\
  \dot{y}&=-\delta y -f(x)+\gamma\cos\psi\\
  \dot{\psi}&=\omega
\end{align*}
Now let's look at the section 
\[
\Sigma=\left\{\left(x,y,\psi\right) : \psi=0\, \mod 2\pi  \right\}
\]
where $T=2\pi/\omega$. This is convenient because our Poincaré map becomes 
\begin{align*}
  \dot{x}&=y\\
  \dot{y}&=-\delta y -f(x)+\gamma\\
\end{align*}
where we could linearize around some closed orbit $\zeta$ to get 
\[ \dot{\xi}= D_xf(\zeta)\cdot \xi \]
Here, $D_xf(\zeta)$ is the Jacobian
\[ J_f(x,y) = \begin{bmatrix}
\frac{\partial f_1}{\partial x} & \frac{\partial f_1}{\partial y} \\
\frac{\partial f_2}{\partial x} & \frac{\partial f_2}{\partial y} 
\end{bmatrix} \]
with the quantities being 
\begin{gather*}
  \frac{\partial f_1}{\partial x}=0\\
  \frac{\partial f_1}{\partial y}=1\\
  \frac{\partial f_2}{\partial x}=-f'(x)\\
  \frac{\partial f_2}{\partial y}=-\delta
\end{gather*}
Putting it all together, the Jacobian is
\[ J_f(x,y) = \begin{bmatrix}
0 & 1 \\
-f'(x) & -\delta
\end{bmatrix} \]
and our Poincare map is 
\[ X(T)=e^{TJ_f}. \]

\mathhint{Nudge}{2026-02-17 18:05}{You're making good progress setting up the linearization, but be careful — the Jacobian $J_f$ evaluated along your periodic orbit is *time-dependent* (since $x(t)$ varies), so $e^{TJ_f}$ isn't quite right. Think about what the correct expression for the fundamental matrix solution looks like when the coefficient matrix depends on $t$.}
Putting it all together, we can write the Jacobian as
\[ A(t)=J_f(x(t),y) = \begin{bmatrix}
0 & 1 \\
-f'(x(t)) & -\delta
\end{bmatrix} \]
and our Poincare map is 
\[ \dot{\xi}= A(t) \xi. \]

\mathhint{Nudge}{2026-02-17 18:10}{You've correctly identified that $A(t)$ is time-dependent, which is the key insight. Now, for the specific case $f(x) = x$, what does $f'(x)$ simplify to, and what does that tell you about whether $A(t)$ is actually time-dependent or constant?}
Now looking at the orbit in part (a), we have $-f'(x)=-1$. Thus our Jacobian at the stable orbit is 
\[ J_f(x(0),y(0)) = \begin{bmatrix}
0 & 1 \\
-1 & -\delta
\end{bmatrix} \]
where $x(0),y(0)$ is 
\[ x(0)=\frac{\gamma}{\delta}\sin 0=0 \]
and 
\[ y(0)=\dot{x}(0)=\frac{\gamma}{\delta}\cos 0 =\frac{\gamma}{\delta}\]
Evaluating our eigenvalues and eigenvectors via SymPy, we have 
\[
\left[ \left( \lambda_0 = - \frac{\delta}{2} - \frac{\sqrt{\delta^2-4}}{2}, \  v_0= \left[\begin{matrix}\lambda_1\\1\end{matrix}\right]\right), \  \left(\lambda_1= - \frac{\delta}{2} + \frac{\sqrt{\delta^2-4}}{2}, \  v_1= \left[\begin{matrix}\lambda_0\\1\end{matrix}\right]\right)\right]
\]
where our eigenvalues $\lambda_0,\lambda_1$ always have a negative real part since $\delta>0$, $\delta<2$ implies that $\sqrt{\delta^2-4}$ is imaginary, and for $\delta>2$ we have $\delta>\sqrt{\delta^2-4}$, implying $\lambda_1$ is negative.

From this, we can conclude that the periodic orbit we found in part (a) is stable.

\mathhint{Nudge}{2026-02-17 19:33}{You're on the right track recognizing that the eigenvalues of $A$ have negative real part, but remember — the stability of the periodic orbit is determined by the eigenvalues of the **Poincaré map** (i.e., $e^{\lambda_i T}$), not the eigenvalues of $A$ directly. Make sure you connect the two explicitly to complete the argument.}
Ah good point.

Note that our time-periodic linear system is 
\[ \dot{\xi}= A \xi \]
where $A$ was our time-independent Jacobian evaluated at the closed orbit. To get the Poincaré map, we integrate this system to get 
\[\xi(T)=\xi(0)e^{TA} \]
where our eigenvalues $\lambda_0,\lambda_1$ of $A$ become eigenvalues $e^{\lambda_0},e^{\lambda_1}$ of the Poincaré map. Hence, because $\lambda_0,\lambda_1$ both had negative real parts, $e^{\lambda_0},e^{\lambda_1}$ are both less than one, implying that the map is stable around our closed orbit.

Note that even if $\lambda$ is complex with a negative real part, we can write 
\[ e^\lambda=e^{\mathrm{Re} \lambda+i\,\mathrm{Im} \lambda}=e^{\mathrm{Re} \lambda}e^{i\,\mathrm{Im} \lambda}=e^{\mathrm{Re} \lambda}\left(\cos(\mathrm{Im} \lambda\right)+i\,\sin\left(\cos(\mathrm{Im} \lambda)\right)\]
which will have a length less than 1. Hence, even if $\lambda$ is complex with a negative real part, the Poincaré map is still stable.

\mathhint{Nudge}{2026-02-17 20:11}{You're almost there — just be careful with the exponents. The eigenvalues of the Poincaré map should be $e^{\lambda_i T}$, not $e^{\lambda_i}$. Make sure the factor of $T = 2\pi$ appears in your final argument.}
Oh sure.

Note that our time-periodic linear system is 
\[ \dot{\xi}= A \xi \]
where $A$ was our time-independent Jacobian evaluated at the closed orbit. To get the Poincaré map, we integrate this system to get 
\[\xi(T)=\xi(0)e^{TA} \]
where our eigenvalues $\lambda_0,\lambda_1$ of $A$ become eigenvalues $e^{\lambda_0T},e^{\lambda_1T}$ of the Poincaré map. Hence, because $\lambda_0,\lambda_1$ both had negative real parts, $e^{\lambda_0T},e^{\lambda_1T}$ are both less than one, implying that the map is stable around our closed orbit.

Note that even if $\lambda$ is complex with a negative real part, we can write 
\[ e^(\lambda T)=e^{T\mathrm{Re} \lambda+i\,T\mathrm{Im} \lambda}=e^{T\mathrm{Re} \lambda}e^{i\,T\mathrm{Im} \lambda}=e^{T\mathrm{Re} \lambda}\left(\cos\left(T\mathrm{Im} \lambda\right)+i\,\sin\left(T\mathrm{Im} \lambda\right)\right)\]
which will have a length less than 1. Hence, even if $\lambda$ is complex with a negative real part, the Poincaré map is still stable.

\mathhint{Nudge}{2026-02-17 20:17}{Your argument for part (b) now looks complete and correct — nice work! Time to move on to part (c).}

\section{Part (c)}

Now letting $f(x)=\sin x$ and fixing $\delta=\gamma=0$, our system is 
\[
\ddot{x}+\sin x =0
\]
and via reparameterizing, we have 
\begin{align*}
  \dot{x}&=y\\
  \dot{y}&=-\sin x
\end{align*}

First, let's find the fixed points to show that a hyperbolic saddle point exists. We can write 
\begin{align*}
  0&=\dot{x}=y\\
  0&=\dot{y}=-\sin x
\end{align*}
where it becomes clear that our fixed points are $(\pm n\pi,0)$ for $n\in\mathbb{Z}$. To linearize, we can compute the Jacobian 
\[ J_f(x,y) = \begin{bmatrix}
\frac{\partial f_1}{\partial x} & \frac{\partial f_1}{\partial y} \\
\frac{\partial f_2}{\partial x} & \frac{\partial f_2}{\partial y} 
\end{bmatrix} \]
with the quatities being 
\begin{gather*}
  \frac{\partial f_1}{\partial x}=0\\
  \frac{\partial f_1}{\partial y}=1\\
  \frac{\partial f_2}{\partial x}=-\cos x\\
  \frac{\partial f_2}{\partial y}=0
\end{gather*}
Now we can compute our linearized matrices 
\begin{gather*}
  Df(0,0)=\begin{bmatrix}
    0 & 1\\
    -1 & 0
  \end{bmatrix}\\
  Df(+\pi,0)=\begin{bmatrix}
    0 & 1\\
    1 & 0
  \end{bmatrix}
\end{gather*}

Notice that I only calculated the Jacobian matrices for $0,+\pi$ since more multiples of $\pi$ will be one of these two matrices. 

Calculating the eigenvalues and eigenvectors, for equilibria $(0,0)$ and corresponding $2\pi$ multiples, we have 
\[\left[ \left( \lambda=- i, \  v= \left[\begin{matrix}i\\1\end{matrix}\right]\right), \  \left( \lambda=i, \  v=\left[\begin{matrix}- i\\1\end{matrix}\right]\right)\right]
\]
implying that linearization tells us nothing since we have 0 real part to our eigenvalues.

Calculating the eigenvalues and eigenvectors, for equilibria $(+\pi,0)$ and corresponding $2\pi$ multiples, we have 
\[\left[ \left( \lambda=-1, \  v=\left[\begin{matrix}-1\\1\end{matrix}\right]\right), \  \left( \lambda=1, \  v= \left[\begin{matrix}1\\1\end{matrix}\right]\right)\right]\] 
where we have an unstable fixed point due to the positive eigenvalue. Specifically, it is a saddle.

Given the hint, we can recognize that the system is Hamiltonian, and go looking for such Hamiltonian. We start by solving for $\partial H/\partial y$
\begin{gather*}
  \frac{\partial H}{\partial y}=y\\
  \partial H = y\partial y\\
  \int \partial H = \int y\partial y\\
  H(x,y) = \frac{y^2}{2}+f(x)
\end{gather*}
and by solving for $\partial H/\partial x$, we have 
\begin{gather*}
  -\frac{\partial H}{\partial x}=-\sin x\\
  \partial H = \sin x \,\partial x\\
  \int \partial H = \int \sin x \,\partial x\\
  H(x,y) = -\cos x +g(y)
\end{gather*}
Putting it all together, we have 
\[ H(x,y) = \frac{y^2}{2} - \cos x \]

Plugging in our saddle point $(\pi,0)$ to our Hamiltonian, we have 
\[
H(\pi,0)=\frac{0^2}{2}-\cos\pi=1
\]
Now to show that there is a homoclinic orbit $q^0(t)$ to the hyperbolic saddle point $p_0=(\pi,0)$, we can use the Hamiltonian to get an expression for y in terms of x, and then we can show that this expression goes to $p_0$. Hence, we can write 
\begin{gather*}
  \frac{y^2}{2} - \cos x=1\\
  y^2=2\left(\cos x + 1\right)\\
  y=\pm\sqrt{2\left(\cos x + 1\right)}
\end{gather*}

\mathhint{Nudge}{2026-02-17 20:47}{You're on the right track with the level set $H = 1$. To finish, think about what happens to $y = \pm\sqrt{2(\cos x + 1)}$ as $x \to \pm\pi$ — does this curve connect $p_0$ back to itself?}

For $y=\pm\sqrt{2\left(\cos x + 1\right)}$, as $x$ goes from $+\pi$ to $-\pi$, we have $(\pi,0)$ to $(-\pi,0)$. But aren't $(\pi,0)$ and $(-\pi,0)$ both different saddle points? Doesn't this mean that we have a heteroclinic orbit?

\mathhint{Nudge}{2026-02-17 21:40}{You're asking exactly the right question! Think about the phase portrait on the **cylinder** — since $\sin x$ is $2\pi$-periodic, $x = -\pi$ and $x = +\pi$ represent the *same* physical state.}
Ah you're right.

Given that the system is $2\pi$-periodic in $x$, our saddle points at $(\pi,0)$ and $(-\pi,0)$ are really the same saddle point. This makes sense given that this system is a damped driven oscillator. Hence, if we start at $(\pi,0)$, and travel along either $+\sqrt{2(\cos x + 1)}$ or $-\sqrt{2(\cos x + 1)}$, we will make it back to $(-\pi,0)$, the same saddle point. Hence, we have a homoclinic orbit.

\mathhint{Nudge}{2026-02-17 21:51}{Your argument for part (c) is solid — nice work connecting the level set back to the same point on the cylinder! You're ready to tackle the numerical parts (d) and (e).}

\section{Part (d)}

I guess I'm confused by what it means to construct a numerical approximation to the Poincaré map. Don't we already have the Poincaré map from part (b)?

\mathhint{Nudge}{2026-02-17 22:19}{You're right that you understand the *concept* of the Poincaré map from part (b), but now with $f(x) = \sin x$, you can't solve the system analytically — so you'll need to **numerically integrate** the ODE from $t=0$ to $t=T$ to evaluate the map for any given initial condition.}
Okay! So we can numerically approximate what trajectories will do over one $T$, and then use the numerical root finder to find an initial condition that is nearly (hopefully exactly) the same after $T$.

\mathhint{Nudge}{2026-02-17 22:22}{That's exactly the right idea — you've got the conceptual framework down perfectly. Go ahead and implement it!}
Here is the code:
\begin{lstlisting}
import numpy as np
import matplotlib.pyplot as plt 

from scipy.integrate import solve_ivp
from scipy import optimize


def driven_pendulum(t, z):
    delta, gamma, omega = 0.5, 1.2, 1.0
    x, y = z
    dx = y
    dy = -delta*y - np.sin(x) + gamma*np.cos(omega*t)
    return [dx,dy]

def residual(y0):
    t_span = (0, 2*np.pi)
    sol = solve_ivp(
        driven_pendulum, t_span, y0, 
        t_eval=np.linspace(0, 2*np.pi, 300)
    )
    return [sol.y[0][-1] - y0[0], sol.y[1][-1] - y0[1]]

guess = [1.0, 0.0]
result = optimize.root(residual, guess, method='hybr')
print(f"Success: {result.success}")
print(f"Periodic orbit initial condition: {result.x}")

t_span = (0, 2*np.pi)
y0 = result.x
sol = solve_ivp(
  driven_pendulum, t_span, y0, 
  t_eval=np.linspace(0, 2*np.pi, 300)
)
plt.plot(sol.t, sol.y[0], label=r'$x$')
plt.plot(sol.t, sol.y[1], label=r'$\dot{x}$')
plt.title(
  "A periodic orbit found via optimization of numerical approximation"
)
plt.legend()
plt.savefig('problem_3_d.png')
plt.show()
\end{lstlisting}

\begin{figure}[h]
\caption{Periodic orbit}
\centering
\includegraphics[width=0.75\textwidth]{problem_3_d.png}
\end{figure}

\mathhint{Nudge}{2026-02-18 10:10}{Your numerical implementation for part (d) looks great — the code and plot are convincing. Now move on to part (e) and think about how to use the Jacobian of your Poincaré map at that fixed point to identify the stable and unstable directions.}

\section{Part (e)}

So the Jacobian is going to be the same as the Jacobian we computed in part (b)? That makes sense. So it would be 
\[ J_f(x,\dot{x}) = \begin{bmatrix}
0 & 1 \\
-\cos x & -\delta
\end{bmatrix} \]

We could then numerically approximate the stable and unstable eigenvectors and then initialize a bunch of points along those directions. When the problem statement says to iterated the forward or backward using our Poincaré map, I suppose this means to use our solve ivp method from part (d). But how would we show transversal intersections? Would we just plot these trajectories in 2 dimensions $(x,\dot{x})$ and then show that some of these trajectories started on the stable and unstable manifolds cross? This feels like the homoclinic tangle. We also are tasked with finding $\delta,\gamma$ for which these transversal intersections occur, which then requires us to recompute the periodic orbit from part (d). 

\mathhint{Nudge}{2026-02-18 11:05}{You're thinking about this correctly — but be careful: the Jacobian of the *Poincaré map* is not the same as the Jacobian of the *vector field*. You need to numerically approximate $DP$ (e.g., via finite differences of your Poincaré map), and then its eigenvectors give you the stable/unstable directions at the fixed point.}

I see. So the $J_f(x,\dot{x})$ I wrote above is not the correct Jacobian. We need to approximate the Jacobian of our approximated Poincaré map from part (d)?

\mathhint{Nudge}{2026-02-18 11:13}{Exactly right — use finite differences of your Poincaré map to build that $2\times 2$ Jacobian matrix numerically, then find its eigenvectors to get your stable/unstable directions. You've got the plan, now implement it!}
What if the eigenvectors it finds are complex?

\mathhint{Nudge}{2026-02-18 11:26}{If you're getting complex eigenvectors, that means the fixed point is a spiral (stable or unstable) rather than a saddle — try adjusting your parameters $\delta$ and $\gamma$ (guided by the hint's inequality) to find a regime where the fixed point is a saddle with real eigenvalues.}

Alright, now let's compute some potential values for $\gamma,\delta$. Let's just say $\delta=0.01$ and then compute what $\gamma$ might be. Hence we can write 
\[\gamma > 0.01\left(\frac{4}{\pi}\cosh\left(\frac{\pi\omega}{2}\right)\right)=0.03195 \]
and we could set $\gamma=0.2$.

Here is the code:
\begin{lstlisting}
def poincare_map(y0):
    t_span = (0, 2*np.pi)
    sol = solve_ivp(driven_pendulum, t_span, y0, dense_output=True)
    return sol.y[:, -1]

def jacobian_finite_diff(y0, diff=1e-6):
    J = np.zeros((2, 2))
    yT = poincare_map(y0)
    
    for i in range(2):
        y_perturbed = y0.copy()
        y_perturbed[i] += diff
        yT_perturbed = poincare_map(y_perturbed)
        J[:, i] = (yT_perturbed - yT) / diff
    
    return J

# Approximate stable and unstable eigenspaces
jacobian = jacobian_finite_diff(y0)
eigen_comps = np.linalg.eig(jacobian)

eps = 0.0001

# Iterate a point on the unstable manifold forward
y_unstable = y0 + eps*eigen_comps.eigenvectors[:,0]
sol_unstable = solve_ivp(
    driven_pendulum, (0, 2*np.pi), y_unstable, 
    t_eval=np.linspace(0, 2*np.pi, 300)
)

# Iterate a point on the stable manifold backward
y_stable = y0 + eps*eigen_comps.eigenvectors[:,1]

sol_stable = solve_ivp(
    driven_pendulum, (0, -2*np.pi), y_stable, 
    t_eval=np.linspace(0, -2*np.pi, 300)
)

# Plot the manifolds 
plt.plot(sol_unstable.y[0], sol_unstable.y[1], label='Unstable manifold')
plt.plot(sol_stable.y[0], sol_stable.y[1], label='Stable manifold')
plt.title('Stable and unstable manifold approximations')
plt.xlabel(r'$x$')
plt.ylabel(r'$\dot{x}$')
plt.legend()
plt.savefig('problem_3_e_manifolds.png', dpi=150, bbox_inches='tight')
plt.show()
\end{lstlisting}

\mathhint{Nudge}{2026-02-18 13:47}{You're on the right track with the eigenvalue computation and parameter choice, but to see the manifolds properly, remember that you need to **iterate the Poincaré map multiple times** (not just integrate for one period) — place many initial points along each eigendirection and apply the map repeatedly to build up the manifold structure.}
\end{notes}

\begin{solution}

\section{Part (a)}

To show that a $2\pi$-periodic solution to (\ref{eq:prob_3}) exists, let's use the method of undetermined coefficients where we guess that $x(t)$ is 
\[ x(t)=A\cos\left( t\right) + B\sin\left( t\right) \]
and then we can compute the following values 
\begin{align*}
  \dot{x}&=-A\sin\left( t\right)+B\cos\left( t\right)\\
  \ddot{x}&=-A\cos\left( t\right) - B\sin\left( t\right)
\end{align*}
Now we can through our values into the following equation 
\[\ddot{x}+\delta\dot{x}+x=\gamma\cos\left( t\right)\]
to get 
\begin{align*}
  \gamma\cos\left( t\right)&=-A\cos\left( t\right) - B\sin\left( t\right)+\delta\left(-A\sin\left( t\right)+B\cos\left( t\right)\right)+A\cos\left( t\right) + B\sin\left( t\right)\\
  &=-A\delta\sin(t)+B\delta\cos(t)
\end{align*}
where $A=0$ and $B=\frac{\gamma}{\delta}$. Hence our $2\pi$-periodic solution to (\ref{eq:prob_3}) is 
\[x(t)=\frac{\gamma}{\delta}\sin(t) \]

\section{Part (b)}

First, let's reparameterize our system such that it is an autonomous system of ODEs:
\begin{align*}
  \dot{x}&=y\\
  \dot{y}&=-\delta y -f(x)+\gamma\cos\psi\\
  \dot{\psi}&=\omega
\end{align*}
Now let's look at the section 
\[
\Sigma=\left\{\left(x,y,\psi\right) : \psi=0\, \mod 2\pi  \right\}
\]
This is convenient because our system becomes 
\begin{align*}
  \dot{x}&=y\\
  \dot{y}&=-\delta y -f(x)+\gamma\\
\end{align*}
where we could linearize around some closed orbit $\zeta$ to get 
\[ \dot{\xi}= D_xf(\zeta)\cdot \xi \]
Here, $D_xf(\zeta)$ is the Jacobian
\[ J_f(x,y) = \begin{bmatrix}
\frac{\partial f_1}{\partial x} & \frac{\partial f_1}{\partial y} \\
\frac{\partial f_2}{\partial x} & \frac{\partial f_2}{\partial y} 
\end{bmatrix} \]
with the quantities being 
\begin{gather*}
  \frac{\partial f_1}{\partial x}=0\\
  \frac{\partial f_1}{\partial y}=1\\
  \frac{\partial f_2}{\partial x}=-f'(x)\\
  \frac{\partial f_2}{\partial y}=-\delta
\end{gather*}
Putting it all together, the Jacobian is
\[ J_f(x,y) = \begin{bmatrix}
0 & 1 \\
-f'(x) & -\delta
\end{bmatrix} \]
and our Poincaré map is given by Floquet theory by solving $\dot{\xi}= D_xf(\zeta)\cdot \xi$ to get 
\[\xi(t)=\Phi(t)\xi(0)\]
where $\Phi(t)$ is the fundamental solution matrix.

Now looking at the orbit in part (a), we have $-f'(x)=-1$. Thus our Jacobian at the stable orbit is 
\[ A(t)=J_f(x(0),y(0)) = \begin{bmatrix}
0 & 1 \\
-1 & -\delta
\end{bmatrix} \]
where $x(0),y(0)$ is 
\[ x(0)=\frac{\gamma}{\delta}\sin 0=0 \]
and 
\[ y(0)=\dot{x}(0)=\frac{\gamma}{\delta}\cos 0 =\frac{\gamma}{\delta}\]
This is nice because our Jacobian $A(t)$ is time-independent, hence just $A$, and by finding Floquet exponents, we can reason about the stability of the Poincaré map. Evaluating our eigenvalues and eigenvectors of the Jacobian via SymPy, we have 
\[
\left[ \left( \lambda_0 = - \frac{\delta}{2} - \frac{\sqrt{\delta^2-4}}{2}, \  v_0= \left[\begin{matrix}\lambda_1\\1\end{matrix}\right]\right), \  \left(\lambda_1= - \frac{\delta}{2} + \frac{\sqrt{\delta^2-4}}{2}, \  v_1= \left[\begin{matrix}\lambda_0\\1\end{matrix}\right]\right)\right]
\]
where our eigenvalues $\lambda_0,\lambda_1$ always have a negative real part since $\delta>0$, $\delta<2$ implies that $\sqrt{\delta^2-4}$ is imaginary, and for $\delta>2$ we have $\delta>\sqrt{\delta^2-4}$, implying $\lambda_1$ is negative.

To get the Poincaré map, we solve $\dot{\xi}= D_xf(\zeta)\cdot \xi$ to get 
\[\xi(T)=e^{TA}\xi(0) \]
where our Floquet exponents $\lambda_0,\lambda_1$ of $A$ become eigenvalues $e^{\lambda_0T},e^{\lambda_1T}$ of the Poincaré map. Hence, because $\lambda_0,\lambda_1$ both had negative real parts, $e^{\lambda_0T},e^{\lambda_1T}$ are both less than one, implying that the map is stable around our closed orbit.

Note that even if $\lambda$ is complex with a negative real part, we can write 
\[ e^{\lambda T}=e^{T\mathrm{Re} \lambda+i\,T\mathrm{Im} \lambda}=e^{T\mathrm{Re} \lambda}e^{i\,T\mathrm{Im} \lambda}=e^{T\mathrm{Re} \lambda}\left(\cos\left(T\mathrm{Im} \lambda\right)+i\,\sin\left(T\mathrm{Im} \lambda\right)\right)\]
which will have a length less than 1. Hence, even if $\lambda$ is complex with a negative real part, the Poincaré map is still stable.

\section{Part (c)}

Now letting $f(x)=\sin x$ and fixing $\delta=\gamma=0$, our system is 
\[
\ddot{x}+\sin x =0
\]
and via reparameterizing, we have 
\begin{align*}
  \dot{x}&=y\\
  \dot{y}&=-\sin x
\end{align*}

First, let's find the fixed points to show that a hyperbolic saddle point exists. We can write 
\begin{align*}
  0&=\dot{x}=y\\
  0&=\dot{y}=-\sin x
\end{align*}
where it becomes clear that our fixed points are $(\pm n\pi,0)$ for $n\in\mathbb{Z}$. To linearize, we can compute the Jacobian 
\[ J_f(x,y) = \begin{bmatrix}
\frac{\partial f_1}{\partial x} & \frac{\partial f_1}{\partial y} \\
\frac{\partial f_2}{\partial x} & \frac{\partial f_2}{\partial y} 
\end{bmatrix} \]
with the quatities being 
\begin{gather*}
  \frac{\partial f_1}{\partial x}=0\\
  \frac{\partial f_1}{\partial y}=1\\
  \frac{\partial f_2}{\partial x}=-\cos x\\
  \frac{\partial f_2}{\partial y}=0
\end{gather*}
Now we can compute our linearized matrices 
\begin{gather*}
  Df(0,0)=\begin{bmatrix}
    0 & 1\\
    -1 & 0
  \end{bmatrix}\\
  Df(+\pi,0)=\begin{bmatrix}
    0 & 1\\
    1 & 0
  \end{bmatrix}
\end{gather*}

Notice that I only calculated the Jacobian matrices for $0,+\pi$ since more multiples of $\pi$ will be one of these two matrices. 

Calculating the eigenvalues and eigenvectors, for equilibria $(0,0)$ and corresponding $2\pi$ multiples, we have 
\[\left[ \left( \lambda=- i, \  v= \left[\begin{matrix}i\\1\end{matrix}\right]\right), \  \left( \lambda=i, \  v=\left[\begin{matrix}- i\\1\end{matrix}\right]\right)\right]
\]
implying that linearization tells us nothing since we have 0 real part to our eigenvalues.

Calculating the eigenvalues and eigenvectors, for equilibria $(+\pi,0)$ and corresponding $2\pi$ multiples, we have 
\[\left[ \left( \lambda=-1, \  v=\left[\begin{matrix}-1\\1\end{matrix}\right]\right), \  \left( \lambda=1, \  v= \left[\begin{matrix}1\\1\end{matrix}\right]\right)\right]\] 
where we have an unstable fixed point due to the positive eigenvalue. Specifically, it is a saddle.

Given the hint, we can recognize that the system is Hamiltonian, and go looking for such Hamiltonian. We start by solving for $\partial H/\partial y$
\begin{gather*}
  \frac{\partial H}{\partial y}=y\\
  \partial H = y\partial y\\
  \int \partial H = \int y\partial y\\
  H(x,y) = \frac{y^2}{2}+f(x)
\end{gather*}
and by solving for $\partial H/\partial x$, we have 
\begin{gather*}
  -\frac{\partial H}{\partial x}=-\sin x\\
  \partial H = \sin x \,\partial x\\
  \int \partial H = \int \sin x \,\partial x\\
  H(x,y) = -\cos x +g(y)
\end{gather*}
Putting it all together, we have 
\[ H(x,y) = \frac{y^2}{2} - \cos x \]

Plugging in our saddle point $(\pi,0)$ to our Hamiltonian, we have 
\[
H(\pi,0)=\frac{0^2}{2}-\cos\pi=1
\]
Now to show that there is a homoclinic orbit $q^0(t)$ to the hyperbolic saddle point $p_0=(\pi,0)$, we can use the Hamiltonian to get an expression for y in terms of x, and then we can show that this expression goes to $p_0$. Hence, we can write 
\begin{gather*}
  \frac{y^2}{2} - \cos x=1\\
  y^2=2\left(\cos x + 1\right)\\
  y=\pm\sqrt{2\left(\cos x + 1\right)}
\end{gather*}

Given that the system is $2\pi$-periodic in $x$, our saddle points at $(\pi,0)$ and $(-\pi,0)$ are really the same saddle point. This makes sense given that this system is a driven pendulum. Hence, if we start at $(\pi,0)$, and travel along either $+\sqrt{2(\cos x + 1)}$ or $-\sqrt{2(\cos x + 1)}$, we will make it back to $(-\pi,0)$, the same saddle point. Hence, we have a homoclinic orbit.

Note that our curves $y=\pm\sqrt{2\left(\cos x + 1\right)}$ don't intersect with our only other fixed point at $(0,0)$. This is because our Hamiltonian evaluated at $(0,0)$ is $H(0,0)=-1$; therefore it lies on a different level set entirely.

\section{Part (d)}

Note that for parts (d) and (e), I did them both simultaneously, so it's relevant to note that I computed some potential values for $\gamma,\delta$ via the hint. Let's just say $\delta=0.01$ and then compute what $\gamma$ might be. Hence we can write 
\[\gamma > 0.01\left(\frac{4}{\pi}\cosh\left(\frac{\pi\omega}{2}\right)\right)=0.03195 \]
and we could set $\gamma=0.2$.

With a generous use of generative AI, I made the following code:
\begin{lstlisting}
import numpy as np
import matplotlib.pyplot as plt 

from scipy.integrate import solve_ivp
from scipy import optimize


def driven_pendulum(t, z):
    delta, gamma, omega = 0.01, 0.2, 1.0
    x, y = z
    dx = y
    dy = -delta*y - np.sin(x) + gamma*np.cos(omega*t)
    return [dx,dy]

def residual(y0):
    t_span = (0, 2*np.pi)
    sol = solve_ivp(
        driven_pendulum, t_span, y0, 
        t_eval=np.linspace(0, 2*np.pi, 300)
    )
    return [sol.y[0][-1] - y0[0], sol.y[1][-1] - y0[1]]

guess = [1.0, 0.0]
result = optimize.root(residual, guess, method='hybr')
print(f"Success: {result.success}")
print(f"Periodic orbit initial condition: {result.x}")

t_span = (0, 2*np.pi)
y0 = result.x
sol = solve_ivp(
  driven_pendulum, t_span, y0, 
  t_eval=np.linspace(0, 2*np.pi, 300)
)
\end{lstlisting}

The identified orbit is indeed a periodic orbit of saddle type, with the eigenvalues being 
\[\lambda_0=5.15278292e+02,\qquad\lambda_1=-1.74208404e-02\]

\begin{figure}[h]
\caption{Periodic orbit}
\centering
\includegraphics[width=0.75\textwidth]{problem_3_d.png}
\end{figure}

\section{Part (e)}

My approach to this problem was to create a Poincaré map from part (d), approximate the Jacobian of the Poincaré map, select two points slightly along the stable and unstable eigenspaces, and iterate them backward and forward respectively.

With a generous use of generative AI, I made the following code:
\begin{lstlisting}
def poincare_map(y0):
    t_span = (0, 2*np.pi)
    sol = solve_ivp(driven_pendulum, t_span, y0, dense_output=True)
    return sol.y[:, -1]

def jacobian_finite_diff(y0, diff=1e-6):
    J = np.zeros((2, 2))
    yT = poincare_map(y0)
    
    for i in range(2):
        y_perturbed = y0.copy()
        y_perturbed[i] += diff
        yT_perturbed = poincare_map(y_perturbed)
        J[:, i] = (yT_perturbed - yT) / diff
    
    return J

# Approximate stable and unstable eigenspaces
jacobian = jacobian_finite_diff(y0)
eigen_comps = np.linalg.eig(jacobian)

eps = 0.0001

# Iterate a point on the unstable manifold forward
y_unstable = y0 + eps*eigen_comps.eigenvectors[:,0]
sol_unstable = solve_ivp(
    driven_pendulum, (0, 2*np.pi), y_unstable, 
    t_eval=np.linspace(0, 2*np.pi, 300)
)

# Iterate a point on the stable manifold backward
y_stable = y0 + eps*eigen_comps.eigenvectors[:,1]

sol_stable = solve_ivp(
    driven_pendulum, (0, -2*np.pi), y_stable, 
    t_eval=np.linspace(0, -2*np.pi, 300)
)
\end{lstlisting}

\begin{figure}[ht]
\caption{Transversal intersection}
\centering
\includegraphics[width=0.75\textwidth]{problem_3_e_manifolds.png}
\end{figure}

Simulating a few trajectories slightly perturbed from $p_0$, we get Figure 4 demonstrating chaotic behavior. Note that trajectories intersect because we are not plotting $\dot{x}$.

\begin{figure}[ht]
\caption{Trajectories demonstrating chaos}
\centering
\includegraphics[width=0.75\textwidth]{spacetime_cylinder.png}
\end{figure}

\end{solution}

\end{document}
